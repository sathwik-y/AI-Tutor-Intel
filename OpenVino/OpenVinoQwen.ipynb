{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOS76Litm9aR"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade optimum[openvino] transformers accelerate huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "59IQSeCNnShQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from optimum.intel.openvino import OVModelForCausalLM\n",
        "import subprocess, os\n",
        "\n",
        "MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "OV_DIR = \"qwen2.5-optimized\"\n",
        "PROMPT = \"Explain Newton's three laws in a fun and simple way.\"\n",
        "RUNS = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup Hugging face access token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GxDVWmwdndbd"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "HF_TOKEN=\"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\"\n",
        "login(HF_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load HF Model and Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "77fbb3a113ea4f54994f0caebbff5041",
            "41af70ce31854b30b4df5e589a1788de",
            "4bad2d4aba1e4e2ea22b08bf46e22e56",
            "ed9bc07f308542439bee185a77d13419",
            "4613c2e038074ebf8b6d33108e7ee105",
            "1c348303e09547dc90cae51556744f2a",
            "88211d7dddda4fa9bffc1309ddae43b7",
            "c31b00c0b0594021a32601d01e888946",
            "d40a0f538b33400aba309203e764c3d0",
            "5761ee437da94f0f9537aff799f1929d",
            "2ecd0ecf3ead43f2bd9c6ce5623751c3"
          ]
        },
        "id": "5F6VuE2anfvQ",
        "outputId": "15433b2f-6c64-49c1-8337-83d207d3aa3d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77fbb3a113ea4f54994f0caebbff5041",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline avg latency: 546.86s\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID,token=HF_TOKEN)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    token=HF_TOKEN,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\"\n",
        ")\n",
        "\n",
        "def benchmark_hf(prompt):\n",
        "    times = []\n",
        "    for _ in range(RUNS):\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        start = time.time()\n",
        "        _ = model.generate(**inputs, max_new_tokens=128)\n",
        "        times.append(time.time() - start)\n",
        "    return sum(times) / len(times)\n",
        "\n",
        "baseline_latency = benchmark_hf(PROMPT)\n",
        "print(f\"Baseline avg latency: {baseline_latency:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimize with OpenVino Optimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by-8-r8fo6cm",
        "outputId": "39be4c5a-c141-4d0b-d919-2fcdf3edd249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n",
            "\rLoading checkpoint shards:   0% 0/4 [00:00<?, ?it/s]\rLoading checkpoint shards: 100% 4/4 [00:00<00:00, 44.38it/s]\n",
            "WARNING:root:Cannot apply model.to_bettertransformer because of the exception:\n",
            "BetterTransformer requires transformers<4.49 but found 4.51.3. `optimum.bettertransformer` is deprecated and will be removed in optimum v2.0.. Usage model with stateful=True may be non-effective if model does not contain torch.functional.scaled_dot_product_attention\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py:457: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  or not self.key_cache[layer_idx].numel()  # the layer has no cache\n",
            "/usr/local/lib/python3.11/dist-packages/optimum/exporters/openvino/model_patcher.py:552: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if sequence_length != 1:\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py:440: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  elif (\n",
            "/usr/local/lib/python3.11/dist-packages/openvino/runtime/__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
            "  warnings.warn(\n",
            "INFO:nncf:Statistics of the bitwidth distribution:\n",
            "┍━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┑\n",
            "│ Weight compression mode   │ % all parameters (layers)   │ % ratio-defining parameters (layers)   │\n",
            "┝━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┥\n",
            "│ int8_asym                 │ 100% (198 / 198)            │ 100% (198 / 198)                       │\n",
            "┕━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┙\n",
            "\u001b[2KApplying Weight Compression \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m • \u001b[36m0:00:41\u001b[0m • \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "if not os.path.isdir(OV_DIR):\n",
        "    !optimum-cli export openvino \\\n",
        "        --model $MODEL_ID \\\n",
        "        --task text-generation-with-past \\\n",
        "        --weight-format int8 \\\n",
        "        $OV_DIR\n",
        "else:\n",
        "    print(\"OpenVINO export directory exists, skipping export.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Benchmarking the optimized model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIY6Q3Hy4JET",
        "outputId": "a6c8eac3-cb46-45f2-949e-2d48b57daf86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenVINO avg latency: 150.26s\n"
          ]
        }
      ],
      "source": [
        "ov_model = OVModelForCausalLM.from_pretrained(OV_DIR)\n",
        "ov_tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=ov_model, tokenizer=ov_tokenizer, device=-1)\n",
        "\n",
        "def benchmark_ov(prompt):\n",
        "    times = []\n",
        "    for _ in range(RUNS):\n",
        "        start = time.time()\n",
        "        _ = pipe(prompt, max_new_tokens=128)\n",
        "        times.append(time.time() - start)\n",
        "    return sum(times) / len(times)\n",
        "\n",
        "ov_latency = benchmark_ov(PROMPT)\n",
        "print(f\"OpenVINO avg latency: {ov_latency:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert the benchmar to CSV & Graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "VECkxROd567w",
        "outputId": "42c16840-764a-47cb-aa66-a53c8a742201"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"HF\", \"OpenVINO INT8\"],\n",
        "    \"Latency (s)\": [baseline_latency, ov_latency],\n",
        "    \"Speedup\": [1, baseline_latency / ov_latency]\n",
        "})\n",
        "\n",
        "results.to_csv(\"llama3.1_benchmark.csv\", index=False)\n",
        "results.plot(kind=\"bar\", x=\"Model\", y=\"Latency (s)\", legend=False, color=[\"orange\", \"green\"])\n",
        "plt.title(\"Llama 3.1 8B Instruct - Latency Comparison\")\n",
        "plt.ylabel(\"Avg Latency (s)\")\n",
        "plt.savefig(\"llama3.1_latency_chart.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDFcsdagBFCq",
        "outputId": "339dd78a-5958-4423-b7f9-a3d7b6e7e04e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: qwen2.5-optimized/ (stored 0%)\n",
            "  adding: qwen2.5-optimized/tokenizer_config.json (deflated 83%)\n",
            "  adding: qwen2.5-optimized/tokenizer.json (deflated 81%)\n",
            "  adding: qwen2.5-optimized/special_tokens_map.json (deflated 69%)\n",
            "  adding: qwen2.5-optimized/merges.txt (deflated 57%)\n",
            "  adding: qwen2.5-optimized/openvino_detokenizer.xml (deflated 79%)\n",
            "  adding: qwen2.5-optimized/openvino_tokenizer.bin (deflated 56%)\n",
            "  adding: qwen2.5-optimized/openvino_detokenizer.bin (deflated 54%)\n",
            "  adding: qwen2.5-optimized/vocab.json (deflated 61%)\n",
            "  adding: qwen2.5-optimized/config.json (deflated 48%)\n",
            "  adding: qwen2.5-optimized/generation_config.json (deflated 39%)\n",
            "  adding: qwen2.5-optimized/openvino_tokenizer.xml (deflated 86%)\n",
            "  adding: qwen2.5-optimized/openvino_model.bin (deflated 12%)\n",
            "  adding: qwen2.5-optimized/openvino_model.xml (deflated 94%)\n",
            "  adding: qwen2.5-optimized/added_tokens.json (deflated 67%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r qwen7b-optimized.zip qwen2.5-optimized\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c348303e09547dc90cae51556744f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecd0ecf3ead43f2bd9c6ce5623751c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41af70ce31854b30b4df5e589a1788de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c348303e09547dc90cae51556744f2a",
            "placeholder": "​",
            "style": "IPY_MODEL_88211d7dddda4fa9bffc1309ddae43b7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4613c2e038074ebf8b6d33108e7ee105": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bad2d4aba1e4e2ea22b08bf46e22e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31b00c0b0594021a32601d01e888946",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d40a0f538b33400aba309203e764c3d0",
            "value": 4
          }
        },
        "5761ee437da94f0f9537aff799f1929d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77fbb3a113ea4f54994f0caebbff5041": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41af70ce31854b30b4df5e589a1788de",
              "IPY_MODEL_4bad2d4aba1e4e2ea22b08bf46e22e56",
              "IPY_MODEL_ed9bc07f308542439bee185a77d13419"
            ],
            "layout": "IPY_MODEL_4613c2e038074ebf8b6d33108e7ee105"
          }
        },
        "88211d7dddda4fa9bffc1309ddae43b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c31b00c0b0594021a32601d01e888946": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d40a0f538b33400aba309203e764c3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed9bc07f308542439bee185a77d13419": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5761ee437da94f0f9537aff799f1929d",
            "placeholder": "​",
            "style": "IPY_MODEL_2ecd0ecf3ead43f2bd9c6ce5623751c3",
            "value": " 4/4 [00:00&lt;00:00, 47.64it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
