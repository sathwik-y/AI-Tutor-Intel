<!DOCTYPE html>
<html>
<head>
    <title>üß† SAGE - Smart Classroom Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        .header {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 20px;
        }
        
        .feature-section {
            background: white;
            margin: 15px 0;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        button {
            padding: 10px 20px;
            font-size: 16px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .primary-btn {
            background-color: #667eea;
            color: white;
        }
        
        .primary-btn:hover {
            background-color: #5a6fd8;
        }
        
        .danger-btn {
            background-color: #f44336;
            color: white;
        }
        
        .success-btn {
            background-color: #4CAF50;
            color: white;
        }
        
        .recording {
            background-color: #ff6b6b !important;
            animation: pulse 1s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: bold;
        }
        
        .connected { background-color: #e8f5e8; color: #2e7d32; }
        .error { background-color: #ffebee; color: #c62828; }
        .info { background-color: #e3f2fd; color: #1976d2; }
        .processing { background-color: #fff3e0; color: #f57c00; }
        
        .response-box {
            border: 1px solid #ddd;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            min-height: 80px;
            background-color: #f9f9f9;
        }
        
        .llm-response {
            background-color: #e3f2fd;
        }
        
        input, textarea, select {
            width: 100%;
            padding: 10px;
            margin: 5px 0;
            border: 1px solid #ddd;
            border-radius: 5px;
            box-sizing: border-box;
        }
        
        .file-upload {
            border: 2px dashed #ddd;
            padding: 20px;
            text-align: center;
            border-radius: 5px;
            margin: 10px 0;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
            gap: 10px;
            margin: 10px 0;
        }
        
        .stat-card {
            background: #667eea;
            color: white;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
        }
        
        .tts-controls {
            background: #f0f8ff;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
            border-left: 4px solid #667eea;
        }
        
        .auto-tts-toggle {
            display: flex;
            align-items: center;
            gap: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üß† SAGE - Smart Classroom Assistant</h1>
        <p>AI-Powered Learning with Speech, Vision, and Knowledge Base</p>
    </div>

    <!-- TTS Settings -->
    <div class="feature-section">
        <h3>üîä Audio Settings</h3>
        <div class="auto-tts-toggle">
            <label>
                <input type="checkbox" id="autoTTS" checked> 
                Automatic Speech Output (recommended for classroom)
            </label>
        </div>
        
        <div class="tts-controls">
            <button class="primary-btn" onclick="testTTS()">üîä Test Speaker</button>
            <button class="primary-btn" onclick="loadVoices()">üé≠ Load Voices</button>
            <span id="ttsStatus" class="status info">Auto-TTS enabled</span>
        </div>
        
        <!-- Voice Controls -->
        <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 10px; margin: 10px 0;">
            <div>
                <label>Voice:</label>
                <select id="voiceSelect" onchange="updateVoiceSettings()">
                    <option value="">Loading voices...</option>
                </select>
            </div>
            <div>
                <label>Speed: <span id="speedValue">180</span> WPM</label>
                <input type="range" id="speedSlider" min="50" max="300" value="180" 
                       oninput="updateSpeedDisplay(); updateVoiceSettings()">
            </div>
            <div>
                <label>Volume: <span id="volumeValue">90</span>%</label>
                <input type="range" id="volumeSlider" min="0" max="100" value="90" 
                       oninput="updateVolumeDisplay(); updateVoiceSettings()">
            </div>
        </div>
    </div>

    <!-- Real-time Audio Query -->
    <div class="feature-section">
        <h3>üé§ Voice Assistant</h3>
        <div>
            <button id="startBtn" class="success-btn" onclick="startRecording()">üé§ Start Listening</button>
            <button id="stopBtn" class="danger-btn" onclick="stopRecording()" disabled>‚èπ Stop & Process</button>
        </div>
        
        <div id="audioStatus" class="status">Ready to listen...</div>
        
        <div>
            <h4>üìù Student Question:</h4>
            <div id="transcript" class="response-box">Transcript will appear here...</div>
        </div>
        
        <div>
            <h4>ü§ñ SAGE Response:</h4>
            <div id="llmResponse" class="response-box llm-response">Response will appear here...</div>
        </div>
    </div>

    <!-- Text Query -->
    <div class="feature-section">
        <h3>üí¨ Text Query</h3>
        <textarea id="textQuery" placeholder="Ask SAGE anything about the course material..." rows="3"></textarea>
        <button class="primary-btn" onclick="submitTextQuery()">üí¨ Ask SAGE</button>
        <div id="textResponse" class="response-box llm-response"></div>
    </div>

    <!-- Document Upload -->
    <div class="feature-section">
        <h3>üìö Knowledge Base</h3>
        <div class="file-upload">
            <input type="file" id="pdfFile" accept=".pdf">
            <button class="primary-btn" onclick="uploadPDF()">üì§ Upload PDF to Knowledge Base</button>
        </div>
        <div id="uploadStatus" class="status"></div>
    </div>

    <!-- Image Analysis -->
    <div class="feature-section">
        <h3>üì∏ Image Analysis</h3>
        <div class="file-upload">
            <input type="file" id="imageFile" accept="image/*">
            <textarea id="imageQuery" placeholder="What would you like to know about this image?" rows="2">What information can you extract from this image?</textarea>
            <button class="primary-btn" onclick="analyzeImage()">üîç Analyze Image</button>
        </div>
        <div id="imageResponse" class="response-box llm-response"></div>
    </div>

    <!-- Attendance System -->
    <div class="feature-section">
        <h3>üë• Attendance Tracker</h3>
        
        <!-- Camera Section -->
        <div style="margin-bottom: 20px;">
            <h4>üì∑ Live Camera Attendance</h4>
            <div style="display: flex; gap: 10px; margin: 10px 0;">
                <button class="primary-btn" onclick="startCamera()">üì∑ Start Camera</button>
                <button class="primary-btn" onclick="captureAttendance()" id="captureBtn" disabled>üì∏ Capture & Count</button>
                <button class="danger-btn" onclick="stopCamera()" id="stopCameraBtn" disabled>‚èπ Stop Camera</button>
            </div>
            
            <div style="display: flex; gap: 20px; align-items: flex-start;">
                <div>
                    <video id="cameraVideo" width="320" height="240" style="border: 2px solid #ddd; border-radius: 8px; display: none;"></video>
                    <canvas id="captureCanvas" width="320" height="240" style="border: 2px solid #ddd; border-radius: 8px; display: none;"></canvas>
                </div>
                <div style="flex: 1;">
                    <div id="cameraStatus" class="status">Camera ready to start</div>
                    <div id="liveCount" style="font-size: 1.5em; font-weight: bold; color: #667eea; margin: 10px 0;">
                        Live Count: <span id="liveCountNumber">0</span>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- File Upload Section -->
        <div>
            <h4>üì§ Upload Image for Attendance</h4>
            <div class="file-upload">
                <input type="file" id="attendanceImage" accept="image/*">
                <button class="primary-btn" onclick="processAttendance()">üìä Count Students from Image</button>
                <button class="primary-btn" onclick="getAttendanceStats()">üìà View Stats</button>
            </div>
        </div>
        
        <div class="stats-grid" id="attendanceStats" style="display: none;">
            <div class="stat-card">
                <div id="currentCount">0</div>
                <div>Current Count</div>
            </div>
            <div class="stat-card">
                <div id="avgAttendance">0</div>
                <div>Average</div>
            </div>
            <div class="stat-card">
                <div id="maxAttendance">0</div>
                <div>Maximum</div>
            </div>
            <div class="stat-card">
                <div id="totalRecords">0</div>
                <div>Records</div>
            </div>
        </div>
        
        <div id="attendanceResponse" class="response-box"></div>
    </div>

    <script>
        let socket = null;
        let mediaRecorder = null;
        let stream = null;
        let isRecording = false;
        let currentAudio = null;
        let cameraStream = null;
        let video = null;
        let canvas = null;

        // Auto-TTS functionality
        async function speakText(text) {
            const autoTTS = document.getElementById('autoTTS').checked;
            if (!autoTTS || !text) return;

            try {
                // Stop any currently playing audio
                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null;
                }

                document.getElementById('ttsStatus').textContent = 'Generating speech...';
                
                const response = await fetch('/api/tts/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: text })
                });

                if (response.ok) {
                    const data = await response.json();
                    
                    // Play the generated audio
                    currentAudio = new Audio(data.audio_url);
                    currentAudio.play();
                    
                    document.getElementById('ttsStatus').textContent = 'üîä Speaking...';
                    
                    currentAudio.onended = () => {
                        document.getElementById('ttsStatus').textContent = 'Ready for next response';
                    };
                    
                } else {
                    console.error('TTS failed');
                    document.getElementById('ttsStatus').textContent = 'TTS error';
                }
            } catch (error) {
                console.error('TTS error:', error);
                document.getElementById('ttsStatus').textContent = 'TTS unavailable';
            }
        }

        function testTTS() {
            speakText("Hello! I'm SAGE, your smart classroom assistant. I'm ready to help with your questions.");
        }

        function updateStatus(elementId, message, className = '') {
            const element = document.getElementById(elementId);
            element.textContent = message;
            element.className = `status ${className}`;
        }

        // WebSocket Audio Functions
        function connectWebSocket() {
            socket = new WebSocket("ws://localhost:8000/ws/transcribe");
            
            socket.onopen = () => {
                updateStatus('audioStatus', "üé§ Connected - Recording in progress...", "connected");
            };

            socket.onmessage = (event) => {
                try {
                    const data = JSON.parse(event.data);
                    
                    switch (data.type) {
                        case 'chunk_received':
                            updateStatus('audioStatus', `Recording... (${data.chunk_count} chunks)`, "connected");
                            break;
                        case 'processing':
                            updateStatus('audioStatus', data.message, "processing");
                            document.getElementById('transcript').textContent = "üîÑ Processing your audio...";
                            break;
                        case 'final_transcript':
                            document.getElementById('transcript').textContent = data.text;
                            updateStatus('audioStatus', "Transcript ready, thinking...", "processing");
                            break;
                        case 'generating':
                            updateStatus('audioStatus', data.message, "processing");
                            break;
                        case 'llm_response':
                            document.getElementById('llmResponse').textContent = data.text;
                            updateStatus('audioStatus', "‚úÖ Complete! Ready for next question.", "connected");
                            
                            // Auto-speak the response
                            speakText(data.text);
                            break;
                        case 'error':
                            updateStatus('audioStatus', `‚ùå Error: ${data.message}`, "error");
                            break;
                    }
                } catch (e) {
                    console.error("Failed to parse message:", e);
                }
            };

            socket.onclose = () => {
                document.getElementById('startBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                isRecording = false;
                
                if (document.getElementById('audioStatus').textContent.includes('Processing')) {
                    updateStatus('audioStatus', "üîÑ Processing complete audio...", "processing");
                }
            };
        }

        async function startRecording() {
            try {
                connectWebSocket();
                await new Promise(resolve => setTimeout(resolve, 500));
                
                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { sampleRate: 16000, channelCount: 1, echoCancellation: true } 
                });
                
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0 && socket && socket.readyState === WebSocket.OPEN) {
                        event.data.arrayBuffer().then(buffer => socket.send(buffer));
                    }
                };
                
                mediaRecorder.start(1000);
                isRecording = true;
                
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('startBtn').className = 'success-btn recording';
                
                document.getElementById('transcript').textContent = "üé§ Listening... Speak your question now!";
                document.getElementById('llmResponse').textContent = "Waiting for your question...";
                
            } catch (error) {
                updateStatus('audioStatus', `‚ùå Error: ${error.message}`, "error");
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
            }
            
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            
            // Close WebSocket to trigger processing
            if (socket && socket.readyState === WebSocket.OPEN) {
                socket.close();
            }
            
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            document.getElementById('startBtn').className = 'success-btn';
            
            updateStatus('audioStatus', "üîÑ Processing your recording...", "processing");
        }

        // Text Query
        async function submitTextQuery() {
            const query = document.getElementById('textQuery').value;
            if (!query.trim()) return;

            try {
                const response = await fetch('/api/query/text', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ query: query })
                });

                const data = await response.json();
                document.getElementById('textResponse').textContent = data.answer;
                
                // Auto-speak the response
                speakText(data.answer);
                
            } catch (error) {
                document.getElementById('textResponse').textContent = `Error: ${error.message}`;
            }
        }

        // PDF Upload
        async function uploadPDF() {
            const fileInput = document.getElementById('pdfFile');
            if (!fileInput.files[0]) return;

            const formData = new FormData();
            formData.append('file', fileInput.files[0]);

            try {
                updateStatus('uploadStatus', 'Uploading and processing PDF...', 'processing');
                
                const response = await fetch('/api/upload-pdf', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                updateStatus('uploadStatus', `‚úÖ ${data.status}`, 'connected');
                
            } catch (error) {
                updateStatus('uploadStatus', `‚ùå Error: ${error.message}`, 'error');
            }
        }

        // Image Analysis
        async function analyzeImage() {
            const fileInput = document.getElementById('imageFile');
            const query = document.getElementById('imageQuery').value;
            
            if (!fileInput.files[0]) return;

            const formData = new FormData();
            formData.append('file', fileInput.files[0]);
            formData.append('query', query);

            try {
                const response = await fetch('/api/query/image', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                document.getElementById('imageResponse').textContent = data.answer;
                
                // Auto-speak the response
                speakText(data.answer);
                
            } catch (error) {
                document.getElementById('imageResponse').textContent = `Error: ${error.message}`;
            }
        }

        // Camera Attendance Functions
        async function startCamera() {
            try {
                video = document.getElementById('cameraVideo');
                canvas = document.getElementById('captureCanvas');
                
                // Get camera access
                cameraStream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        width: 640, 
                        height: 480,
                        facingMode: 'environment' // Use back camera if available
                    } 
                });
                
                video.srcObject = cameraStream;
                video.style.display = 'block';
                video.play();
                
                // Enable capture button
                document.getElementById('captureBtn').disabled = false;
                document.getElementById('stopCameraBtn').disabled = false;
                
                updateStatus('cameraStatus', 'üì∑ Camera active - ready to capture!', 'connected');
                
                // Auto-detect faces every 3 seconds for live count
                startLiveDetection();
                
            } catch (error) {
                console.error('Camera error:', error);
                updateStatus('cameraStatus', `‚ùå Camera error: ${error.message}`, 'error');
            }
        }

        function startLiveDetection() {
            if (!cameraStream) return;
            
            const detectInterval = setInterval(() => {
                if (!cameraStream) {
                    clearInterval(detectInterval);
                    return;
                }
                
                // Capture frame silently for live count
                captureFrameForCount();
            }, 3000); // Update every 3 seconds
        }

        async function captureFrameForCount() {
            if (!video || !canvas) return;
            
            try {
                const ctx = canvas.getContext('2d');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                ctx.drawImage(video, 0, 0);
                
                // Convert to blob and send for counting (silent)
                canvas.toBlob(async (blob) => {
                    const formData = new FormData();
                    formData.append('file', blob, 'live_frame.jpg');
                    
                    try {
                        const response = await fetch('/api/attendance/upload', {
                            method: 'POST',
                            body: formData
                        });
                        
                        if (response.ok) {
                            const data = await response.json();
                            document.getElementById('liveCountNumber').textContent = data.headcount;
                        }
                    } catch (error) {
                        // Silent fail for live updates
                        console.log('Live count update failed:', error);
                    }
                }, 'image/jpeg', 0.8);
                
            } catch (error) {
                console.error('Frame capture error:', error);
            }
        }

        async function captureAttendance() {
            if (!video || !canvas) return;
            
            try {
                updateStatus('cameraStatus', 'üì∏ Capturing attendance...', 'processing');
                
                const ctx = canvas.getContext('2d');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                ctx.drawImage(video, 0, 0);
                
                // Show captured image
                canvas.style.display = 'block';
                video.style.display = 'none';
                
                // Convert to blob and upload
                canvas.toBlob(async (blob) => {
                    const formData = new FormData();
                    formData.append('file', blob, 'attendance_capture.jpg');
                    
                    try {
                        const response = await fetch('/api/attendance/upload', {
                            method: 'POST',
                            body: formData
                        });
                        
                        const data = await response.json();
                        
                        document.getElementById('attendanceResponse').innerHTML = `
                            <strong>üìä Attendance Captured!</strong><br>
                            <strong>Headcount: ${data.headcount} students detected</strong><br>
                            Timestamp: ${new Date(data.timestamp).toLocaleString()}<br>
                            Detection Method: ${data.detection_method}<br>
                            Session ID: ${data.session_id}
                            ${data.annotated_image_url ? `<br><img src="${data.annotated_image_url}" style="max-width: 100%; margin-top: 10px;">` : ''}
                        `;
                        
                        document.getElementById('currentCount').textContent = data.headcount;
                        document.getElementById('liveCountNumber').textContent = data.headcount;
                        
                        updateStatus('cameraStatus', '‚úÖ Attendance recorded successfully!', 'connected');
                        
                        // Auto-announce attendance
                        speakText(`Attendance captured! I detected ${data.headcount} students in the classroom.`);
                        
                        // Show video again after 3 seconds
                        setTimeout(() => {
                            if (cameraStream) {
                                video.style.display = 'block';
                                canvas.style.display = 'none';
                            }
                        }, 3000);
                        
                    } catch (error) {
                        updateStatus('cameraStatus', `‚ùå Upload error: ${error.message}`, 'error');
                    }
                }, 'image/jpeg', 0.9);
                
            } catch (error) {
                updateStatus('cameraStatus', `‚ùå Capture error: ${error.message}`, 'error');
            }
        }

        function stopCamera() {
            if (cameraStream) {
                cameraStream.getTracks().forEach(track => track.stop());
                cameraStream = null;
            }
            
            video = document.getElementById('cameraVideo');
            canvas = document.getElementById('captureCanvas');
            
            if (video) {
                video.style.display = 'none';
                video.srcObject = null;
            }
            
            if (canvas) {
                canvas.style.display = 'none';
            }
            
            document.getElementById('captureBtn').disabled = true;
            document.getElementById('stopCameraBtn').disabled = true;
            document.getElementById('liveCountNumber').textContent = '0';
            
            updateStatus('cameraStatus', 'Camera stopped', 'info');
        }

        // Attendance Processing (existing function for file upload)
        async function processAttendance() {
            const fileInput = document.getElementById('attendanceImage');
            if (!fileInput.files[0]) return;

            const formData = new FormData();
            formData.append('file', fileInput.files[0]);

            try {
                const response = await fetch('/api/attendance/upload', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                
                document.getElementById('attendanceResponse').innerHTML = `
                    <strong>Headcount: ${data.headcount} students detected</strong><br>
                    Timestamp: ${new Date(data.timestamp).toLocaleString()}<br>
                    Session ID: ${data.session_id}
                    ${data.annotated_image_url ? `<br><img src="${data.annotated_image_url}" style="max-width: 100%; margin-top: 10px;">` : ''}
                `;
                
                document.getElementById('currentCount').textContent = data.headcount;
                
                // Auto-announce attendance
                speakText(`I detected ${data.headcount} students in the classroom.`);
                
            } catch (error) {
                document.getElementById('attendanceResponse').textContent = `Error: ${error.message}`;
            }
        }

        // Attendance Stats
        async function getAttendanceStats() {
            try {
                const response = await fetch('/api/attendance/stats');
                const data = await response.json();
                
                document.getElementById('attendanceStats').style.display = 'grid';
                document.getElementById('avgAttendance').textContent = Math.round(data.average_attendance);
                document.getElementById('maxAttendance').textContent = data.max_attendance;
                document.getElementById('totalRecords').textContent = data.total_records;
                
                const statsText = `Attendance statistics: Average ${Math.round(data.average_attendance)} students, Maximum ${data.max_attendance} students, Total ${data.total_records} records.`;
                speakText(statsText);
                
            } catch (error) {
                console.error('Stats error:', error);
            }
        }

        // Auto-cleanup
        window.addEventListener('beforeunload', () => {
            if (isRecording) stopRecording();
            if (currentAudio) currentAudio.pause();
            if (cameraStream) stopCamera();
        });

        // Initialize voices on page load
        window.addEventListener('load', () => {
            loadVoices();
        });
        async function loadVoices() {
            try {
                const response = await fetch('/api/tts/voices');
                const data = await response.json();
                
                const voiceSelect = document.getElementById('voiceSelect');
                voiceSelect.innerHTML = '<option value="">Select Voice</option>';
                
                data.voices.forEach((voice, index) => {
                    const option = document.createElement('option');
                    option.value = index;
                    option.textContent = voice.name;
                    voiceSelect.appendChild(option);
                });
                
                // Load current settings
                const statusResponse = await fetch('/api/tts/status');
                const statusData = await statusResponse.json();
                
                if (statusData.settings) {
                    document.getElementById('voiceSelect').value = statusData.settings.voice_index;
                    document.getElementById('speedSlider').value = statusData.settings.rate;
                    document.getElementById('volumeSlider').value = Math.round(statusData.settings.volume * 100);
                    updateSpeedDisplay();
                    updateVolumeDisplay();
                }
                
            } catch (error) {
                console.error('Failed to load voices:', error);
            }
        }

        function updateSpeedDisplay() {
            document.getElementById('speedValue').textContent = document.getElementById('speedSlider').value;
        }

        function updateVolumeDisplay() {
            document.getElementById('volumeValue').textContent = document.getElementById('volumeSlider').value;
        }

        async function updateVoiceSettings() {
            try {
                const settings = {
                    voice_index: parseInt(document.getElementById('voiceSelect').value) || 0,
                    rate: parseInt(document.getElementById('speedSlider').value),
                    volume: parseFloat(document.getElementById('volumeSlider').value) / 100
                };

                const response = await fetch('/api/tts/settings', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(settings)
                });

                if (response.ok) {
                    document.getElementById('ttsStatus').textContent = 'Settings updated!';
                    setTimeout(() => {
                        document.getElementById('ttsStatus').textContent = 'Ready for next response';
                    }, 2000);
                }
            } catch (error) {
                console.error('Failed to update settings:', error);
            }
        }

        // Poll for transcription results
        async function pollForResults(sessionId, attempts = 0) {
            const maxAttempts = 30; // 30 seconds max
            
            console.log(`Polling for session ${sessionId}, attempt ${attempts + 1}`);
            
            try {
                const response = await fetch(`/api/transcribe-result/${sessionId}`);
                
                if (response.ok) {
                    const data = await response.json();
                    console.log('Got result:', data);
                    
                    if (data.error) {
                        updateStatus('audioStatus', `‚ùå Error: ${data.error}`, "error");
                        document.getElementById('transcript').textContent = `Error: ${data.error}`;
                        return;
                    }
                    
                    // Success! Display results
                    document.getElementById('transcript').textContent = data.transcript;
                    document.getElementById('llmResponse').textContent = data.response;
                    updateStatus('audioStatus', "‚úÖ Complete! Ready for next question.", "connected");
                    
                    // Auto-speak the response
                    speakText(data.response);
                    
                } else if (response.status === 202) {
                    // Still processing, try again
                    console.log('Still processing...');
                    if (attempts < maxAttempts) {
                        setTimeout(() => pollForResults(sessionId, attempts + 1), 1000);
                    } else {
                        updateStatus('audioStatus', "‚ùå Processing timeout", "error");
                    }
                } else if (response.status === 404) {
                    console.error('Session not found on server');
                    updateStatus('audioStatus', "‚ùå Session not found", "error");
                } else {
                    console.error('Unexpected response:', response.status);
                    updateStatus('audioStatus', "‚ùå Failed to get results", "error");
                }
                
            } catch (error) {
                console.error('Polling error:', error);
                if (attempts < maxAttempts) {
                    setTimeout(() => pollForResults(sessionId, attempts + 1), 1000);
                } else {
                    updateStatus('audioStatus', "‚ùå Connection error", "error");
                }
            }
        }
    </script>
</body>
</html>